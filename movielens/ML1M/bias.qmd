---
title: Bias on ML1M
echo: false
deps:
- sweeps/random/bias-random
---

This page analyzes the hyperparameter tuning results for the bias model.

```{python}
from codex.reporting.prelude import *
```

```{python}
sweep_dir = Path('sweeps/random')
model_name = 'bias'
```

```{python}
with open(sweep_dir / f'{model_name}-random' / 'trials.ndjson', 'rt') as jsf:
    run_data = [json.loads(line) for line in jsf]
random_runs = pd.json_normalize(run_data)
```

## Metric Response

How does RMSE change with each setting independently?

::: {.panel-tabset}

### User Damping

```{python}
(
    pn.ggplot(random_runs)
    + pn.aes(x='config.damping.user', y='RMSE')
    + pn.geom_point()
)
```

### Item Damping

```{python}
(
    pn.ggplot(random_runs)
    + pn.aes(x='config.damping.item', y='RMSE')
    + pn.geom_point()
)
```

:::

## Best Configurations

Since this is an explicit-feedback rating prediction model, our primary search
criteria is RMSE. The configuration with the best RMSE is:

```{python}
pd.concat({
    'Random': random_runs.nsmallest(1, 'RMSE')[['config.damping.user', 'config.damping.item', 'RBP', 'RMSE']],
}, names=['Method']).reset_index(-1, drop=True)
```

If we instead searched for RBP, we would select:

```{python}
pd.concat({
    'Random': random_runs.nlargest(1, 'RBP')[['config.damping.user', 'config.damping.item', 'RBP', 'RMSE']],
}, names=['Method']).reset_index(-1, drop=True)
```

## Search Geometry

What is the geometry of the search space?

```{python}
(
    pn.ggplot(random_runs)
    + pn.aes(x='config.damping.user', y='config.damping.item')
    + pn.geom_density_2d()
    + pn.scale_x_log10()
    + pn.scale_y_log10()
)
```
