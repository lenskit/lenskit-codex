---
title: ML100K Performance Summary
order: 1
deps:
- run-summary.csv
- run-user-metrics.parquet
---

This is a summary view of model performance on the ML100K data set.

```{python}
from codex.reporting.prelude import *
```

```{python}
runs = pd.read_csv('run-summary.csv')
runs = runs[runs['part'] != 0]
user_metrics = pd.read_parquet('run-user-metrics.parquet')
user_metrics = user_metrics[user_metrics['part'] != 0]
```

## Top-N Recommendation Accuracy

::: {.panel-tabset}

### RBP

```{python}
(
    pn.ggplot(user_metrics)
    + pn.aes(x='model', y='RBP', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.geom_errorbar(position='dodge', stat='summary')
    + pn.scale_fill_brewer('qual', 'Dark2')
    + pn.coord_flip()
)
```

### NDCG

```{python}
(
    pn.ggplot(user_metrics)
    + pn.aes(x='model', y='NDCG', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.geom_errorbar(position='dodge', stat='summary')
    + pn.scale_fill_brewer('qual', 'Dark2')
    + pn.coord_flip()
)
```

### MRR

```{python}
(
    pn.ggplot(user_metrics)
    + pn.aes(x='model', y='RecipRank', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.geom_errorbar(position='dodge', stat='summary')
    + pn.scale_fill_brewer('qual', 'Dark2')
    + pn.coord_flip()
)
```

:::

## Rating Prediction Accuracy

```{python}
pred_metrics = user_metrics[user_metrics['RMSE'].notnull()]
(
    pn.ggplot(pred_metrics)
    + pn.aes(x='model', y='RMSE', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.geom_errorbar(position='dodge', stat='summary')
    + pn.scale_fill_brewer('qual', 'Dark2')
)
```

## Resource Consumption

### Time

```{python}
rtime = runs.melt(id_vars=['variant', 'model', 'part'], value_vars=['train_cpu', 'train_time', 'infer_time', 'infer_cpu'])
rtime = rtime.groupby(['variant', 'model', 'variable'])['value'].sum().reset_index()
rtime['stage'] = rtime['variable'].str.split('_', expand=True)[0]
rtime['type'] = rtime['variable'].str.split('_', expand=True)[1]
rtime.loc[rtime['type'] == 'time', 'type'] = 'wall'
(
    pn.ggplot(rtime)
    + pn.aes(x='model', y='value', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.facet_grid('stage ~ type', scales="free_x")
    + pn.ylab("Total time (seconds)")
    + pn.coord_flip()
    + pn.scale_fill_brewer(type="qual", palette="Dark2")
)
```

### Memory

```{python}
(
    pn.ggplot(runs)
    + pn.aes(x='model', y='train_mem', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.ylab("Avg training memory")
    + scale_y_memory()
    + pn.coord_flip()
    + pn.scale_fill_brewer(type="qual", palette="Dark2")
)
```

### Power

```{python}
rpow = runs.melt(id_vars=['variant', 'model', 'part'], value_vars=['train_power', 'infer_power'])
rpow = rpow.groupby(['variant', 'model', 'variable'])['value'].sum().reset_index()
rpow['stage'] = rpow['variable'].str.split('_', expand=True)[0]
(
    pn.ggplot(rpow)
    + pn.aes(x='model', y='value', fill='variant')
    + pn.geom_col(position='dodge')
    + pn.facet_grid('~ stage', scales="free_x")
    + pn.ylab("Total power (Joules)")
    + pn.coord_flip()
    + pn.scale_fill_brewer(type="qual", palette="Dark2")
)
```

## Leaderboard Table

This provides quick numeric access to the model results by mean metric.  Note, however,
that simple means can be misleading!

```{python}
run_summary = user_metrics.groupby(['model', 'variant'], observed=True)[['RBP', 'NDCG', 'RecipRank']].mean()
run_summary = run_summary.sort_values('RBP', ascending=False)
show_df(run_summary.style.format("{:.3f}"))
```
