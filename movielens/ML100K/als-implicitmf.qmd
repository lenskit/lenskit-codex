---
title: ALS ImplicitMF on ML100K
echo: false
deps:
- sweeps/random/ImplicitMF-ALS.duckdb
outs:
- sweeps/random/ImplicitMF-ALS.csv
- sweeps/random/ImplicitMF-ALS.json
---

```{python}
from os import fspath
from pathlib import Path
import json
```

```{python}
import pandas as pd
import numpy as np
import plotnine as pn
import matplotlib.pyplot as plt
import duckdb
```

```{python}
from sandal import autoroot
from codex.display import DEFAULTS
```

```{python}
sweep_dir = Path('sweeps/random')
sweep_name = 'ImplicitMF-ALS'
rnd_sweep = duckdb.connect(fspath(sweep_dir / f'{sweep_name}.duckdb'), read_only=True)
```

## Parameter Sweeps

For the per-user random crossfolding data split, we use the first partition of
the fold for parameter tuning.

### Top-N Ranking

```{python}
cfg_ndcg = rnd_sweep.sql("""
SELECT features, CAST(reg AS varchar) AS reg, AVG(ndcg) AS ndcg
FROM run_specs JOIN user_metrics USING (rec_idx)
GROUP BY features, reg
""").to_df()
(
    pn.ggplot(cfg_ndcg)
    + pn.aes(x='features', y='ndcg', color='reg', shape='reg')
    + pn.geom_line()
    + pn.ylab('Mean nDCG')
    + pn.scale_color_brewer('qual', 'Dark2')
)
```

### Training Time

How long does training take?

```{python}
nf_times = rnd_sweep.sql("""
SELECT features, AVG(wall_time) AS wall, AVG(cpu_time) AS cpu
FROM run_specs JOIN train_metrics USING (rec_idx)
GROUP BY features
""").to_df().melt('features', var_name='type')
nf_times['value'] = pd.to_timedelta(nf_times['value'], unit='s')
(
    pn.ggplot(nf_times)
    + pn.aes(x='features', y='value')
    + pn.geom_line()
    + pn.ylab('Training time')
    + pn.xlab('Latent feature count')
    + pn.scale_y_timedelta()
    + pn.facet_wrap('type', scales='free_y')
)
```

How does training time relate to performance?

```{python}
ranked = rnd_sweep.sql("""
SELECT COLUMNS(rs.* EXCLUDE rec_id),
    wall_time AS TrainTime,
    cpu_time AS TrainCPU,
    rss_max_kb / 1024 AS TrainMemMB,
    AVG(ndcg) AS NDCG,
    AVG(recip_rank) AS MRR,
FROM run_specs rs
JOIN train_metrics tm USING (rec_idx)
JOIN user_metrics USING (rec_idx)
GROUP BY rs.*
ORDER BY ndcg DESC
""")
ranked.to_df()
```

Let's save those results.

```{python}
ranked.write_csv(fspath(sweep_dir / f'{sweep_name}.csv'))
best = dict(zip(ranked.columns, ranked.fetchone()))
json_file = sweep_dir / f'{sweep_name}.json'
json_file.write_text(json.dumps(best))
```
