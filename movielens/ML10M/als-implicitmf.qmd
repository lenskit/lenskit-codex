---
title: ALS ImplicitMF on ML10M
echo: false
deps:
- sweeps/random/ImplicitMF-ALS
---

```{python}
from os import fspath
from pathlib import Path
import json
```

```{python}
import pandas as pd
import numpy as np
import plotnine as pn
import matplotlib.pyplot as plt
import duckdb
```

```{python}
from codex.display import DEFAULTS
```

```{python}
sweep_dir = Path('sweeps/random')
sweep_name = 'ImplicitMF-ALS'

with open(sweep_dir / sweep_name / 'runs.json', 'rt') as jsf:
    run_data = [json.loads(line) for line in jsf]
runs = pd.json_normalize(run_data)
```

## Parameter Sweeps

For the per-user random crossfolding data split, we use the first partition of
the fold for parameter tuning.

### Top-N Ranking

```{python}
cfg_topn = runs.groupby(['params.features', 'params.reg'])[['metrics.RBP', 'metrics.NDCG', 'metrics.RecipRank']].mean().reset_index()
cfg_topn = cfg_topn.astype({'params.reg': 'str'})
(
    pn.ggplot(cfg_topn)
    + pn.aes(x='params.features', y='metrics.RBP', color='params.reg', shape='params.reg')
    + pn.geom_line()
    + pn.ylab('Mean RBP')
    + pn.scale_color_brewer('qual', 'Dark2')
)
```

```{python}
(
    pn.ggplot(cfg_topn)
    + pn.aes(x='params.features', y='metrics.NDCG', color='params.reg', shape='params.reg')
    + pn.geom_line()
    + pn.ylab('Mean NDCG')
    + pn.scale_color_brewer('qual', 'Dark2')
)
```

```{python}
(
    pn.ggplot(cfg_topn)
    + pn.aes(x='params.features', y='metrics.RecipRank', color='params.reg', shape='params.reg')
    + pn.geom_line()
    + pn.ylab('Mean Recip. Rank')
    + pn.scale_color_brewer('qual', 'Dark2')
)
```

### Training Time

How long does training take?

```{python}
nf_times = runs.groupby('params.features')[['train_task.duration', 'train_task.cpu_time']].mean()
nf_times.columns.name = 'type'
nf_times = nf_times.rename(columns={
    'train_task.duration': 'Wall',
    'train_task.cpu_time': 'CPU',
})
nf_times = nf_times.stack().to_frame('value').reset_index()
nf_times['value'] = pd.to_timedelta(nf_times['value'], unit='s')
(
    pn.ggplot(nf_times)
    + pn.aes(x='params.features', y='value')
    + pn.geom_line()
    + pn.ylab('Training time')
    + pn.xlab('Latent feature count')
    + pn.scale_y_timedelta()
    + pn.facet_wrap('type', scales='free_y')
)
```


How much power does training take?

```{python}
nf_power = runs.groupby('params.features')['train_task.chassis_power'].mean().reset_index()
(
    pn.ggplot(nf_power)
    + pn.aes(x='params.features', y='train_task.chassis_power')
    + pn.geom_line()
    + pn.ylab('Average power (J)')
    + pn.xlab('Latent feature count')
)
```
