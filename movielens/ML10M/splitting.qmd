---
title: ML10M Data Splitting
order: 1
deps:
- ratings.duckdb
---

This page describes the analysis done to select the cutoffs for temporally-splitting the ML10M data set.

```{python}
import duckdb
db = duckdb.connect('ratings.duckdb', read_only=True)
```

## Split Windows

Following [@mengExploringDataSplitting2020], we are going to prepare a global temporal split of the rating data.  We will target a 70/15/15 train/tune/test split, but round the timestamps so our test splits are at clean calendar dates.
Searching for quantiles will get us this.

```{python}
db.query('''
SELECT quantile_cont(timestamp, 0.7) AS t_tune,
    quantile_cont(timestamp, 0.85) AS t_test,
FROM ratings
''').df()
```

This suggests that Apr. 2005 is a reasonable tuning cutoff, and 2007 a good test cutoff.

```{python}
t_tune = '2005-04-01'
t_test = '2007-01-01'
```

```{python}
db.query(f'''
SELECT
    CASE WHEN timestamp < '{t_tune}' THEN 'train'
         WHEN timestamp < '{t_test}' THEN 'tune'
         ELSE 'test'
    END AS part,
    count(*) AS n_ratings,
    count(distinct user_id) AS n_users,
    count(distinct item_id) AS n_items
FROM ratings
GROUP BY part
''').df()
```

How many users can we use for collaborative filtering in the testing set?

```{python}
db.query(f'''
SELECT COUNT(DISTINCT user_id) n_users, COUNT(*) n_ratings
FROM ratings
WHERE user_id IN (
    SELECT DISTINCT user_id FROM ratings
    WHERE timestamp < '{t_test}'GROUP BY user_id
    HAVING count(*) >= 5
)
AND timestamp >= '{t_test}'
''').df()
```

And for tuning / validation?

```{python}
db.query(f'''
SELECT COUNT(DISTINCT user_id) n_users, COUNT(*) n_ratings
FROM ratings
WHERE user_id IN (
    SELECT DISTINCT user_id FROM ratings
    WHERE timestamp < '{t_tune}'
    GROUP BY user_id
    HAVING count(*) >= 5
)
AND timestamp >= '{t_tune}'
''').df()
```

This give us enough data to work with, even if we might like more test users.
