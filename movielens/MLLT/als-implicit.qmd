---
title: ALS Implicit
pagetitle: MLLT - ALS Implicit
echo: false
model: als-implicit
deps:
- sweeps/temporal/als-implicit-optuna
---

This page analyzes the hyperparameter tuning results for the implicit-feedback
ALS matrix factorization model.



```{python}
from codex.reporting.prelude import *
```

```{python}
runs = load_sweep_runs('als-implicit')
iters = load_sweep_iters('als-implicit')
result = load_sweep_result('als-implicit')
best_id = result['trial_id']
```

## Parameter Search Space

```{python}
from codex.models.als_implicit import SEARCH_SPACE
show_param_space(SEARCH_SPACE, result['config'])
```

### Final Result

Searching selected the following configuration:

```{python}
rich.print(result['config'])
```

With these metrics:

```{python}
rich.print(result)
```


## Parameter Analysis

### Embedding Size

The embedding size is the hyperparameter that most affects the model's
fundamental logic, so let's look at performance as a fufnction of it:

```{python}
(
    pn.ggplot(runs)
    + pn.aes(x='config.embedding_size_exp', y='RBP')
    + pn.geom_point()
    + pn.xlab("lg(embedding size)")
)
```

### Learning Parameters

::: {.panel-tabset}

#### User Reg.

```{python}
(
    pn.ggplot(runs)
    + pn.aes(x='config.regularization.user', y='RBP')
    + pn.geom_point()
    + pn.scale_x_log10()
    + pn.labs(x='User Regularization')
)
```

#### Item Reg.

```{python}
(
    pn.ggplot(runs)
    + pn.aes(x='config.regularization.item', y='RBP')
    + pn.geom_point()
    + pn.scale_x_log10()
    + pn.labs(x='Item Regularization')
)
```

:::

## Iteration Completion

How many iterations, on average, did we complete?

```{python}
(
    pn.ggplot(runs)
    + pn.aes(x='training_iteration')
    + pn.geom_histogram(binwidth=1)
)
```

How did the metric progress in the best result?

```{python}
best_iters = iters[iters['trial_id'] == best_id]
(
    pn.ggplot(best_iters)
    + pn.aes(x='training_iteration', y='RBP')
    + pn.geom_line()
    + pn.ggtitle(f'Best Progress ({best_id})')
)
```

How did the metric progress in the longest results?

```{python}
max_iter = iters['training_iteration'].max()
last_results = iters[iters['training_iteration'] == max_iter]
full_trials = last_results['trial_id']
full_iters = iters[iters['trial_id'].isin(full_trials)]
(
    pn.ggplot(full_iters)
    + pn.aes(x='training_iteration', y='RBP', color='trial_id')
    + pn.geom_line()
)
```
