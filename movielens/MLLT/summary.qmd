---
title: Performance Summary
pagetitle: MLLT Performance Summary
order: 1
deps:
- run-summary.csv
- run-user-metrics.parquet
---

This is a summary view of model performance on the MLLT data set.



```{python}
DS_NAME = 'MLLT'
PART = 'valid'
```


```{python}
from codex.reporting.prelude import *
```

```{python}
runs = pd.read_csv('run-summary.csv')
runs = filter_part(runs, PART)
user_metrics = pd.read_parquet('run-user-metrics.parquet')
user_metrics = filter_part(user_metrics, PART)
```

## Top-N Recommendation Accuracy

::: {.panel-tabset}

### RBP

```{python}
(
    pn.ggplot(user_metrics)
    + pn.aes(x='model', y='RBP', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.geom_errorbar(position=pn.position_dodge(width=0.9), stat='summary')
    + pn.scale_fill_brewer('qual', 'Dark2')
    + pn.coord_flip()
    + pn.ggtitle(f'Top-N RBP on {DS_NAME} ({PART})')
    + pn.ylab('RBP(0.85)')
)
```

### NDCG

```{python}
(
    pn.ggplot(user_metrics)
    + pn.aes(x='model', y='NDCG', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.geom_errorbar(position=pn.position_dodge(width=0.9), stat='summary')
    + pn.scale_fill_brewer('qual', 'Dark2')
    + pn.coord_flip()
    + pn.ggtitle(f'Top-N NDCG on {DS_NAME} ({PART})')
)
```

### MRR

```{python}
(
    pn.ggplot(user_metrics)
    + pn.aes(x='model', y='RecipRank', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.geom_errorbar(position=pn.position_dodge(width=0.9), stat='summary')
    + pn.scale_fill_brewer('qual', 'Dark2')
    + pn.coord_flip()
    + pn.ggtitle(f'Top-N Reciprocal Rank on {DS_NAME} ({PART})')
)
```

### HR

```{python}
(
    pn.ggplot(user_metrics)
    + pn.aes(x='model', y='Hit', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.geom_errorbar(position=pn.position_dodge(width=0.9), stat='summary')
    + pn.scale_fill_brewer('qual', 'Dark2')
    + pn.coord_flip()
    + pn.ggtitle(f'Top-N HR on {DS_NAME} ({PART})')
)
```

:::

## Rating Prediction Accuracy

```{python}
pred_metrics = user_metrics[user_metrics['RMSE'].notnull()]
(
    pn.ggplot(pred_metrics)
    + pn.aes(x='model', y='RMSE', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.geom_errorbar(position='dodge', stat='summary')
    + pn.scale_fill_brewer('qual', 'Dark2')
)
```

## Resource Consumption

### Time

```{python}
rtime = runs.melt(id_vars=['variant', 'model', 'part'], value_vars=['train_cpu', 'train_time', 'infer_time', 'infer_cpu'])
rtime = rtime.groupby(['variant', 'model', 'variable'])['value'].sum().reset_index()
rtime['stage'] = rtime['variable'].str.split('_', expand=True)[0]
rtime['type'] = rtime['variable'].str.split('_', expand=True)[1]
rtime.loc[rtime['type'] == 'time', 'type'] = 'wall'
(
    pn.ggplot(rtime)
    + pn.aes(x='model', y='value', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.facet_grid('stage ~ type', scales="free_x")
    + pn.ylab("Total time (seconds)")
    + pn.coord_flip()
    + pn.scale_fill_brewer(type="qual", palette="Dark2")
)
```

### Memory

```{python}
(
    pn.ggplot(runs)
    + pn.aes(x='model', y='train_mem', fill='variant')
    + pn.geom_col(position='dodge', stat='summary')
    + pn.ylab("Avg training memory")
    + scale_y_memory()
    + pn.coord_flip()
    + pn.scale_fill_brewer(type="qual", palette="Dark2")
)
```

### Power

::: {.panel-tabset}

#### Energy

```{python}
rpow = runs.melt(id_vars=['variant', 'model', 'part'], value_vars=['train_power', 'infer_power'])
rpow = rpow.groupby(['variant', 'model', 'variable'])['value'].sum().reset_index()
rpow['stage'] = rpow['variable'].str.split('_', expand=True)[0]
rpow['wh'] = rpow['value'] / 3600
rpow['co2'] = rpow['wh'] / 1_000_000 * CONFIG.power.co2e_rate
(
    pn.ggplot(rpow)
    + pn.aes(x='model', y='wh', fill='variant')
    + pn.geom_col(position='dodge')
    + pn.coord_flip()
    + pn.facet_grid('~ stage', scales="free_x")
    + pn.ylab("Total power (Wh)")
    + pn.ggtitle("Estimated Power Consumption")
    + pn.scale_fill_brewer(type="qual", palette="Dark2")
)
```

#### kgCO2

```{python}
(
    pn.ggplot(rpow)
    + pn.aes(x='model', y='co2', fill='variant')
    + pn.geom_col(position='dodge')
    + pn.coord_flip()
    + pn.facet_grid('~ stage', scales="free_x")
    + pn.ylab("Emissions (kgCO2)")
    + pn.ggtitle("Estimated Carbon Emissions")
    + pn.scale_fill_brewer(type="qual", palette="Dark2")
)
```

:::

## Leaderboard Table

This provides quick numeric access to the model results by mean metric.  Note, however,
that simple means can be misleading!

### Top-N Recommendation

```{python}
run_summary = user_metrics.groupby(['model', 'variant'], observed=True)[['RBP', 'NDCG', 'RecipRank', 'RMSE', 'MAE']].mean()
rec_summary = run_summary.sort_values('RBP', ascending=False).drop(columns=[
    'RMSE', 'MAE'
])
show_df(rec_summary.style.format("{:.3f}"), allow_html=True)
```

### Rating Prediction

```{python}
pred_summary = run_summary.loc[
    run_summary['RMSE'].notnull(),
    ['RMSE', 'MAE']
]
pred_summary = pred_summary.sort_values('RMSE')
show_df(pred_summary.style.format("{:.3f}"), allow_html=True)
```
